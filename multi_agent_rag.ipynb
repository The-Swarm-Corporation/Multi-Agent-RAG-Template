{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "Q_kKTSS3Q8ss",
        "outputId": "4113556e-e01d-4977-8bfe-e8e80cd6d2c0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pinecone'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4b056cc41a3c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import required libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpinecone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfaker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFaker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pinecone'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#datagen.py\n",
        "# Import required libraries\n",
        "import os\n",
        "import pinecone\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "from llama_index.embeddings import get_embedding\n",
        "\n",
        "# Initialize Faker and Pinecone\n",
        "fake = Faker()\n",
        "pinecone.init(api_key=os.getenv(\"PINECONE_API_KEY\"), environment=os.getenv(\"PINECONE_ENV\"))\n",
        "pinecone_index = pinecone.Index(\"llama-memory-index\")\n",
        "\n",
        "# Medical-specific data\n",
        "conditions = [\n",
        "    \"Hypertension\", \"Type 2 Diabetes\", \"Asthma\", \"Arthritis\", \"Depression\",\n",
        "    \"Anxiety\", \"GERD\", \"Migraine\", \"Hypothyroidism\", \"Hyperlipidemia\",\n",
        "]\n",
        "\n",
        "medications = [\n",
        "    \"Lisinopril 10mg\", \"Metformin 500mg\", \"Albuterol inhaler\", \"Sertraline 50mg\",\n",
        "    \"Omeprazole 20mg\", \"Levothyroxine 75mcg\", \"Atorvastatin 40mg\", \"Amlodipine 5mg\",\n",
        "    \"Metoprolol 25mg\", \"Gabapentin 300mg\",\n",
        "]\n",
        "\n",
        "allergies = [\n",
        "    \"Penicillin\", \"Sulfa\", \"Latex\", \"Peanuts\", \"Shellfish\", \"Iodine\", \"Aspirin\",\n",
        "    \"Morphine\", \"None\", \"Dairy\",\n",
        "]\n",
        "\n",
        "# Generate patient vitals\n",
        "def generate_vitals():\n",
        "    return {\n",
        "        \"Blood Pressure\": f\"{random.randint(110,140)}/{random.randint(60,90)}\",\n",
        "        \"Heart Rate\": f\"{random.randint(60,100)} bpm\",\n",
        "        \"Temperature\": f\"{round(random.uniform(97.0, 99.5), 1)}Â°F\",\n",
        "        \"Respiratory Rate\": f\"{random.randint(12,20)} breaths/min\",\n",
        "        \"Weight\": f\"{random.randint(120,220)} lbs\",\n",
        "        \"Height\": f\"{random.randint(60,75)} inches\",\n",
        "    }\n",
        "\n",
        "# Generate patient medical history\n",
        "def generate_patient_history():\n",
        "    num_visits = random.randint(3, 8)\n",
        "    history = []\n",
        "    current_date = datetime.now()\n",
        "\n",
        "    for _ in range(num_visits):\n",
        "        visit = {\n",
        "            \"Date\": current_date.strftime(\"%Y-%m-%d\"),\n",
        "            \"Chief Complaint\": fake.sentence(nb_words=4),\n",
        "            \"Vitals\": generate_vitals(),\n",
        "            \"Assessment\": random.sample(conditions, random.randint(1, 3)),\n",
        "            \"Medications\": random.sample(medications, random.randint(1, 4)),\n",
        "            \"Plan\": fake.paragraph(nb_sentences=2),\n",
        "        }\n",
        "        history.append(visit)\n",
        "        current_date -= timedelta(days=random.randint(30, 180))\n",
        "\n",
        "    return history\n",
        "\n",
        "# Send patient document to Pinecone\n",
        "def send_to_pinecone(patient_id, document_text):\n",
        "    \"\"\"Embed and index patient document to Pinecone.\"\"\"\n",
        "    embedding = get_embedding(document_text)  # Generate embedding for the document text\n",
        "    pinecone_index.upsert([(patient_id, embedding)])  # Upsert to Pinecone\n",
        "\n",
        "# Create patient file and save to Pinecone\n",
        "def create_patient_file(patient_id):\n",
        "    \"\"\"Create a patient record and send it to Pinecone.\"\"\"\n",
        "    patient = {\n",
        "        \"Patient ID\": patient_id,\n",
        "        \"Name\": fake.name(),\n",
        "        \"DOB\": fake.date_of_birth(minimum_age=18, maximum_age=90).strftime(\"%Y-%m-%d\"),\n",
        "        \"Gender\": random.choice([\"Male\", \"Female\"]),\n",
        "        \"Contact\": {\n",
        "            \"Phone\": fake.phone_number(),\n",
        "            \"Email\": fake.email(),\n",
        "            \"Address\": fake.address(),\n",
        "        },\n",
        "        \"Insurance\": fake.company(),\n",
        "        \"Allergies\": random.sample(allergies, random.randint(0, 3)),\n",
        "        \"Medical History\": generate_patient_history(),\n",
        "    }\n",
        "\n",
        "    # Create directory if it doesn't exist\n",
        "    if not os.path.exists(\"docs\"):\n",
        "        os.makedirs(\"docs\")\n",
        "\n",
        "    # Write patient data to file\n",
        "    filename = f\"docs/patient_{patient_id}.txt\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(f\"PATIENT MEDICAL RECORD\\n{'='*50}\\n\\n\")\n",
        "        f.write(f\"Patient ID: {patient['Patient ID']}\\n\")\n",
        "        f.write(f\"Name: {patient['Name']}\\n\")\n",
        "        f.write(f\"DOB: {patient['DOB']}\\n\")\n",
        "        f.write(f\"Gender: {patient['Gender']}\\n\\n\")\n",
        "\n",
        "        f.write(\"Contact Information:\\n\")\n",
        "        for key, value in patient[\"Contact\"].items():\n",
        "            f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "        f.write(f\"\\nInsurance: {patient['Insurance']}\\n\")\n",
        "        f.write(\n",
        "            f\"Allergies: {', '.join(patient['Allergies']) if patient['Allergies'] else 'None'}\\n\\n\"\n",
        "        )\n",
        "\n",
        "        f.write(\"MEDICAL HISTORY\\n\")\n",
        "        f.write(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "        for visit in patient[\"Medical History\"]:\n",
        "            f.write(f\"\\nVisit Date: {visit['Date']}\\n\")\n",
        "            f.write(f\"Chief Complaint: {visit['Chief Complaint']}\\n\")\n",
        "\n",
        "            f.write(\"\\nVitals:\\n\")\n",
        "            for k, v in visit[\"Vitals\"].items():\n",
        "                f.write(f\"  {k}: {v}\\n\")\n",
        "\n",
        "            f.write(f\"\\nAssessment: {', '.join(visit['Assessment'])}\\n\")\n",
        "            f.write(f\"Medications: {', '.join(visit['Medications'])}\\n\")\n",
        "            f.write(f\"Plan: {visit['Plan']}\\n\")\n",
        "            f.write(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "    # Send patient file to Pinecone after creation\n",
        "    with open(filename, \"r\") as f:\n",
        "        document_text = f.read()\n",
        "    send_to_pinecone(patient_id, document_text)\n",
        "\n",
        "# Main function to generate patient records\n",
        "def main():\n",
        "    num_patients = 10  # Change this number to generate more or fewer patient records\n",
        "    for i in range(num_patients):\n",
        "        create_patient_file(f\"P{str(i+1).zfill(6)}\")\n",
        "    print(f\"Generated {num_patients} patient records in the 'docs' directory and indexed them in Pinecone.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "    # Cleanup Pinecone at the end\n",
        "    pinecone.deinit()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#agents.py\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from swarms import Agent\n",
        "from swarm_models import OpenAIChat\n",
        "from multi_agent_rag.memory import LlamaIndexDB\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Get the OpenAI API key from the environment variable\n",
        "api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "# Model\n",
        "model = OpenAIChat(\n",
        "    openai_api_base=\"https://api.groq.com/openai/v1\",\n",
        "    openai_api_key=api_key,\n",
        "    model_name=\"llama-3.1-70b-versatile\",\n",
        "    temperature=0.1,\n",
        ")\n",
        "\n",
        "# Initialize memory system\n",
        "memory_system = LlamaIndexDB(\n",
        "    data_dir=\"docs\",  # Directory containing medical documents\n",
        "    filename_as_id=True,  # Use filenames as document identifiers\n",
        "    recursive=True,  # Search subdirectories\n",
        "    similarity_top_k=10,  # Return top 10 most relevant documents\n",
        ")\n",
        "\n",
        "# Initialize specialized medical agents\n",
        "medical_data_extractor = Agent(\n",
        "    agent_name=\"Medical-Data-Extractor\",\n",
        "    system_prompt=\"You are a specialized medical data extraction expert, trained in processing and analyzing clinical data, lab results, medical imaging reports, and patient records. Your role is to carefully extract relevant medical information while maintaining strict HIPAA compliance and patient confidentiality. Focus on identifying key clinical indicators, test results, vital signs, medication histories, and relevant patient history. Ensure all extracted data maintains proper medical context and terminology.\",\n",
        "    llm=model,\n",
        "    max_loops=1,\n",
        "    autosave=True,\n",
        "    verbose=True,\n",
        "    dynamic_temperature_enabled=True,\n",
        "    saved_state_path=\"medical_data_extractor.json\",\n",
        "    user_name=\"medical_team\",\n",
        "    retry_attempts=1,\n",
        "    context_length=200000,\n",
        "    output_type=\"string\",\n",
        "    memory_system=memory_system,  # Attach memory system for retrieval\n",
        ")\n",
        "\n",
        "diagnostic_specialist = Agent(\n",
        "    agent_name=\"Diagnostic-Specialist\",\n",
        "    system_prompt=\"You are a senior diagnostic physician with extensive experience in differential diagnosis. Your role is to analyze patient symptoms, lab results, and clinical findings to develop comprehensive diagnostic assessments. Consider all presenting symptoms, patient history, risk factors, and test results to formulate possible diagnoses. Prioritize diagnoses based on clinical probability and severity. Always consider both common and rare conditions that match the symptom pattern. Recommend additional tests or imaging when needed for diagnostic clarity. Follow evidence-based diagnostic criteria and current medical guidelines.\",\n",
        "    llm=model,\n",
        "    max_loops=1,\n",
        "    autosave=True,\n",
        "    verbose=True,\n",
        "    dynamic_temperature_enabled=True,\n",
        "    saved_state_path=\"diagnostic_specialist.json\",\n",
        "    user_name=\"medical_team\",\n",
        "    retry_attempts=1,\n",
        "    context_length=200000,\n",
        "    output_type=\"string\",\n",
        "    memory_system=memory_system,  # Attach memory system for retrieval\n",
        ")\n",
        "\n",
        "treatment_planner = Agent(\n",
        "    agent_name=\"Treatment-Planner\",\n",
        "    system_prompt=\"You are an experienced clinical treatment specialist focused on developing comprehensive treatment plans. Your expertise covers both acute and chronic condition management, medication selection, and therapeutic interventions. Consider patient-specific factors including age, comorbidities, allergies, and contraindications when recommending treatments. Incorporate both pharmacological and non-pharmacological interventions. Emphasize evidence-based treatment protocols while considering patient preferences and quality of life. Address potential drug interactions and side effects. Include monitoring parameters and treatment milestones.\",\n",
        "    llm=model,\n",
        "    max_loops=1,\n",
        "    autosave=True,\n",
        "    verbose=True,\n",
        "    dynamic_temperature_enabled=True,\n",
        "    saved_state_path=\"treatment_planner.json\",\n",
        "    user_name=\"medical_team\",\n",
        "    retry_attempts=1,\n",
        "    context_length=200000,\n",
        "    output_type=\"string\",\n",
        "    memory_system=memory_system,  # Attach memory system for retrieval\n",
        ")\n",
        "\n",
        "specialist_consultant = Agent(\n",
        "    agent_name=\"Specialist-Consultant\",\n",
        "    system_prompt=\"You are a medical specialist consultant with expertise across multiple disciplines including cardiology, neurology, endocrinology, and internal medicine. Your role is to provide specialized insight for complex cases requiring deep domain knowledge. Analyze cases from your specialist perspective, considering rare conditions and complex interactions between multiple systems. Provide detailed recommendations for specialized testing, imaging, or interventions within your domain. Highlight potential complications or considerations that may not be immediately apparent to general practitioners.\",\n",
        "    llm=model,\n",
        "    max_loops=1,\n",
        "    autosave=True,\n",
        "    verbose=True,\n",
        "    dynamic_temperature_enabled=True,\n",
        "    saved_state_path=\"specialist_consultant.json\",\n",
        "    user_name=\"medical_team\",\n",
        "    retry_attempts=1,\n",
        "    context_length=200000,\n",
        "    output_type=\"string\",\n",
        "    memory_system=memory_system,  # Attach memory system for retrieval\n",
        ")\n",
        "\n",
        "patient_care_coordinator = Agent(\n",
        "    agent_name=\"Patient-Care-Coordinator\",\n",
        "    system_prompt=\"You are a patient care coordinator specializing in comprehensive healthcare management. Your role is to ensure holistic patient care by coordinating between different medical specialists, considering patient needs, and managing care transitions. Focus on patient education, medication adherence, lifestyle modifications, and follow-up care planning. Consider social determinants of health, patient resources, and access to care. Develop actionable care plans that patients can realistically follow. Coordinate with other healthcare providers to ensure continuity of care and proper implementation of treatment plans.\",\n",
        "    llm=model,\n",
        "    max_loops=1,\n",
        "    autosave=True,\n",
        "    verbose=True,\n",
        "    dynamic_temperature_enabled=True,\n",
        "    saved_state_path=\"patient_care_coordinator.json\",\n",
        "    user_name=\"medical_team\",\n",
        "    retry_attempts=1,\n",
        "    context_length=200000,\n",
        "    output_type=\"string\",\n",
        "    memory_system=memory_system,  # Attach memory system for retrieval\n",
        ")\n"
      ],
      "metadata": {
        "id": "jQKS14ljRKMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#__init.py__\n",
        "from .agents import (\n",
        "    medical_data_extractor,\n",
        "    diagnostic_specialist,\n",
        "    treatment_planner,\n",
        "    specialist_consultant,\n",
        "    patient_care_coordinator\n",
        ")\n",
        "from .swarm_models import OpenAIChat\n",
        "\n",
        "# Initialize the model or other common components\n",
        "from .common import initialize_model  # If you have a separate init function for the model\n",
        "\n",
        "# Additional setup or logging if needed\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n"
      ],
      "metadata": {
        "id": "1QE29GoxRiXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#memory.py\n",
        "import os\n",
        "import pinecone\n",
        "from typing import Optional, List\n",
        "from pathlib import Path\n",
        "from loguru import logger\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.embeddings import get_embedding\n",
        "\n",
        "class LlamaPineconeDB:\n",
        "    \"\"\"Manage document indexing and querying using Pinecone and LlamaIndex for memory.\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir: str = \"docs\", pinecone_api_key: str = \"\", pinecone_env: str = \"us-east1-aws\") -> None:\n",
        "        self.data_dir = data_dir\n",
        "        self.index = None\n",
        "\n",
        "        # Initialize Pinecone with the specified environment\n",
        "        pinecone.init(api_key=pinecone_api_key, environment=pinecone_env)\n",
        "        index_name = \"llama-memory-index\"\n",
        "\n",
        "        # Check if the index already exists; if not, create it\n",
        "        if index_name not in pinecone.list_indexes():\n",
        "            pinecone.create_index(index_name, dimension=768)  # assuming 768 for embedding vector size\n",
        "        self.pinecone_index = pinecone.Index(index_name)\n",
        "\n",
        "        logger.info(\"Initialized LlamaPineconeDB\")\n",
        "        data_path = Path(self.data_dir)\n",
        "        if not data_path.exists():\n",
        "            logger.error(f\"Directory not found: {self.data_dir}\")\n",
        "            raise FileNotFoundError(f\"Directory {self.data_dir} does not exist\")\n",
        "\n",
        "        self.add_documents()\n",
        "\n",
        "    def add_documents(self) -> None:\n",
        "        \"\"\"Read and index documents into Pinecone.\"\"\"\n",
        "        try:\n",
        "            documents = SimpleDirectoryReader(self.data_dir).load_data()\n",
        "            for doc in documents:\n",
        "                embedding = get_embedding(doc.text)  # Get embedding for document text\n",
        "                # Use doc id and embedding in upsert\n",
        "                self.pinecone_index.upsert([(doc.id, embedding)])\n",
        "            logger.success(f\"Documents indexed successfully from {self.data_dir}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error indexing documents: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def query(self, query: str, top_k: int = 5) -> List[str]:\n",
        "        \"\"\"Retrieve similar documents using Pinecone and provide memory.\n",
        "\n",
        "        Args:\n",
        "            query (str): The query string.\n",
        "            top_k (int): Number of similar documents to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            List[str]: List of top-k similar document texts.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            query_embedding = get_embedding(query)\n",
        "            results = self.pinecone_index.query(query_embedding, top_k=top_k, include_values=True)\n",
        "\n",
        "            # Retrieve top documents\n",
        "            top_docs = [match['text'] for match in results['matches']]\n",
        "            logger.info(f\"Retrieved {len(top_docs)} documents for query: {query}\")\n",
        "            return top_docs\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during query: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Clean up Pinecone resources.\"\"\"\n",
        "        pinecone.deinit()\n",
        "\n",
        "# Initialize the Pinecone DB using API key from environment variables\n",
        "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")  # Ensure this is set in your environment\n",
        "\n",
        "if pinecone_api_key:\n",
        "    llama_pinecone_db = LlamaPineconeDB(\n",
        "        data_dir=\"docs\",\n",
        "        pinecone_api_key=pinecone_api_key,\n",
        "        pinecone_env=\"us-east1-aws\"  # Free tier environment\n",
        "    )\n",
        "    response = llama_pinecone_db.query(\"What is the medical history of patient 1?\")\n",
        "    print(response)\n",
        "    llama_pinecone_db.close()\n",
        "else:\n",
        "    logger.error(\"Pinecone API key not found. Please set the PINECONE_API_KEY environment variable.\")\n"
      ],
      "metadata": {
        "id": "LuUqHdHVRpJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main.py\n",
        "# Import the AgentRearrange class for coordinating multiple agents\n",
        "from swarms import AgentRearrange\n",
        "\n",
        "# Import specialized medical agents for different aspects of patient care\n",
        "from multi_agent_rag.agents import (\n",
        "    diagnostic_specialist,  # Agent for diagnostic analysis\n",
        "    medical_data_extractor,  # Agent for extracting medical data\n",
        "    patient_care_coordinator,  # Agent for coordinating patient care\n",
        "    specialist_consultant,  # Agent for specialist consultation\n",
        "    treatment_planner,  # Agent for treatment planning\n",
        ")\n",
        "\n",
        "# Import database class for storing and retrieving medical documents\n",
        "from multi_agent_rag.memory import LlamaIndexDB\n",
        "\n",
        "# Initialize the SwarmRouter to coordinate the medical agents\n",
        "router = AgentRearrange(\n",
        "    name=\"medical-diagnosis-treatment-swarm\",\n",
        "    description=\"Collaborative medical team for comprehensive patient diagnosis and treatment planning\",\n",
        "    max_loops=1,  # Limit to one iteration through the agent flow\n",
        "    agents=[\n",
        "        medical_data_extractor,  # First agent to extract medical data\n",
        "        diagnostic_specialist,  # Second agent to analyze and diagnose\n",
        "        treatment_planner,  # Third agent to plan treatment\n",
        "        specialist_consultant,  # Fourth agent to provide specialist input\n",
        "        patient_care_coordinator,  # Final agent to coordinate care plan\n",
        "    ],\n",
        "    # Configure the document storage and retrieval system\n",
        "    memory_system=LlamaIndexDB(\n",
        "        data_dir=\"docs\",  # Directory containing medical documents\n",
        "        filename_as_id=True,  # Use filenames as document identifiers\n",
        "        recursive=True,  # Search subdirectories\n",
        "        similarity_top_k=10,  # Return top 10 most relevant documents\n",
        "    ),\n",
        "    # Define the sequential flow of information between agents\n",
        "    flow=f\"{medical_data_extractor.agent_name} -> {diagnostic_specialist.agent_name} -> {treatment_planner.agent_name} -> {specialist_consultant.agent_name} -> {patient_care_coordinator.agent_name}\",\n",
        ")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Run a comprehensive medical analysis task for patient Lucas Brown\n",
        "    patient_data = \"Patient Lucas Brown's medical data goes here.\"  # Example input\n",
        "    router.run(patient_data)  # Pass the patient data through the agent flow\n"
      ],
      "metadata": {
        "id": "MROXfBcfRuLl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}